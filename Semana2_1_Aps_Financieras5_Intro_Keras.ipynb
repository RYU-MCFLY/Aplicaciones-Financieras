{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RYU-MCFLY/Aplicaciones-Financieras/blob/main/Semana2_1_Aps_Financieras5_Intro_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0k09TS_IMVm"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MaxMitre/Aplicaciones-Financieras/blob/main/Semana2/1_Intro_Keras.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6ycg5V95HY2"
      },
      "source": [
        "# Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQFMcdzeBA6x"
      },
      "outputs": [],
      "source": [
        "# Puede no ser necesaria si ya tienen instalado plotly\n",
        "# !pip install -U plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRgTSOxpISdc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, mean_squared_error, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwVzeQRtAEzI"
      },
      "outputs": [],
      "source": [
        "pio.templates.default = 'plotly_white'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U-nHaVB5KBi"
      },
      "source": [
        "# Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFbnxLqr89h5"
      },
      "source": [
        "Utilizaremos los mismo datos de la clase pasada\n",
        "\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud/data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxgb5q9ZZ4Hh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNzqDP5CSrzl"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Cruso-ApsFinancieras/semana3/creditcard.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXaachuDrMvR"
      },
      "outputs": [],
      "source": [
        "# El resultado seria 'False' si NO hay valores nulos y sería 'True' si SI hay valores nulos\n",
        "df.isnull().values.any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2erSguIeUVTK"
      },
      "outputs": [],
      "source": [
        "# 0: Normal\n",
        "# 1: Fraudulento\n",
        "\n",
        "print(df.Class.value_counts())\n",
        "df.Class.value_counts() / len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTRSkuq8U5su"
      },
      "outputs": [],
      "source": [
        "df[df.Class == 0].Amount.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cE2fCZTVR90"
      },
      "outputs": [],
      "source": [
        "df[df.Class == 1].Amount.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpocjVmMD1hA"
      },
      "outputs": [],
      "source": [
        "df.loc[:, 'V1':'Amount']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTVW67kmaAoW"
      },
      "outputs": [],
      "source": [
        "# Separación de características\n",
        "X = df.iloc[:, 1:-1]\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGJuxX37byk0"
      },
      "outputs": [],
      "source": [
        "# Variables objetivos\n",
        "y = df.Class\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu-TExSOrtv7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP7elYAFsoWb"
      },
      "outputs": [],
      "source": [
        "normal_df = df[df.Class == 0]\n",
        "fraud_df = df[df.Class == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_ssJgHIrpgb"
      },
      "outputs": [],
      "source": [
        "bins = np.linspace(200, 2500, 100)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
        "\n",
        "ax = axes.ravel()\n",
        "\n",
        "ax[0].hist(normal_df.Amount, bins, alpha=1, label='Normal')\n",
        "ax[0].set_title('legitime', fontsize=20)\n",
        "\n",
        "ax[1].hist(fraud_df.Amount, bins, alpha=1, label='Fraud')\n",
        "ax[1].set_title('fraud', fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-A1bs_T5NWh"
      },
      "source": [
        "## División en conjuntos de entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cePk6kYu7IL"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10) # train_size=0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIpQn-qd5Y9d"
      },
      "source": [
        "## Estandarización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz7nk32wyBXR"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_norm = scaler.transform(X_train)\n",
        "\n",
        "pd.DataFrame(X_train_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVP4geWErCz1"
      },
      "source": [
        "\"If you torture the data long enough, it will confess\" Ronald H. Coase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_DWBLWn5nAv"
      },
      "source": [
        "# Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyG3LD1j5r7c"
      },
      "source": [
        "## Configuración del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFXWRZU-b7eN"
      },
      "outputs": [],
      "source": [
        "input_dim = X_train_norm.shape[1] # Número de columnas: 29\n",
        "encoding_dim = 14\n",
        "hidden_dim = int(encoding_dim / 2) \n",
        "learning_rate = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jzneWo6oi3M"
      },
      "outputs": [],
      "source": [
        "hidden_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfXIX0VbYK6f"
      },
      "outputs": [],
      "source": [
        "print(f'{1e-5: .9f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfUz2Djs5u_h"
      },
      "source": [
        "## Arquitectura de la red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GQtw5Sj1wgP"
      },
      "outputs": [],
      "source": [
        "# Hiperparámetros muy importantes:\n",
        "# - learning rate\n",
        "# - batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2aHBpB0wMbk"
      },
      "outputs": [],
      "source": [
        "# Creación de las capas del modelo\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim, activation=\"relu\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
        "encoder2 = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
        "\n",
        "decoder = Dense(hidden_dim, activation='relu')(encoder2)\n",
        "decoder_f = Dense(input_dim, activation='relu')(decoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder_f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3Ahzdco76H2"
      },
      "outputs": [],
      "source": [
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK45y4nksxrg"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(loss='mean_squared_error',\n",
        "                    optimizer='adam')\n",
        "\n",
        "### Con las lineas de abajo pueden decidir que epoca de entrenamiento guardar\n",
        "\n",
        "# cp = ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
        "#                                save_best_only=True,\n",
        "#                                verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkwDpJZv5yrc"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvkv9m9wcm4i"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(X_train_norm, X_train_norm,\n",
        "                          epochs=100,\n",
        "                          batch_size=2048,\n",
        "                          shuffle = True,\n",
        "                          validation_split=.2,\n",
        "                          verbose=1, \n",
        "                        #   callbacks = cp\n",
        "                          ).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7qOMq_qyPxW"
      },
      "outputs": [],
      "source": [
        "# Comando para recuperar los datos guardados del modelos, en este caso se guardaria la mejor epoca nada mas\n",
        "\n",
        "# autoencoder = load_model('autoencoder_fraud.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf-ZP8rN51jH"
      },
      "source": [
        "## Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOVJ5A0S0Ucx"
      },
      "outputs": [],
      "source": [
        "# Grafica de la pérdida del modelo en el tiempo\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(y = history['loss'], name = 'loss'))\n",
        "fig.add_trace(go.Scatter(y = history['val_loss'], name = 'val_loss'))\n",
        "fig.update_layout(\n",
        "    title = 'Pérdida del modelo',\n",
        "    xaxis_title = 'Época (epoch)', \n",
        "    yaxis_title = 'Pérdida (MSE)'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tXT7oOy0X6Z"
      },
      "outputs": [],
      "source": [
        "X_test_norm = scaler.transform(X_test)\n",
        "X_test_pred = autoencoder.predict(X_test_norm)\n",
        "\n",
        "# Error cuadratico medio, a mano\n",
        "mse = mean_squared_error(X_test_norm.T, X_test_pred.T, multioutput = 'raw_values')\n",
        "error_df = pd.DataFrame({'Reconstruction_error': mse,\n",
        "                        'True_class': y_test})\n",
        "error_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFHHHhRSZcVJ"
      },
      "outputs": [],
      "source": [
        "error_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbxYgcLpEctG"
      },
      "source": [
        "La precision y el recall son muy importantes, y a veces hay que buscar el modo de optimizarlos escogiendo un threshold adecuado.\n",
        "\n",
        "El limite a escoger (threshold) depende de que se desea del modelo. Escoger si preferimos dejar pasar un fraude por etiquetarlo mal o si preferimos etiquetar mas como fraude e invertir en solucionarlos aunque no sean fraude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8z_8hLk70WB"
      },
      "outputs": [],
      "source": [
        "precision_rt, recall_rt, threshold_rt = precision_recall_curve(error_df.True_class, error_df.Reconstruction_error)\n",
        "px.scatter(x = recall_rt, y = precision_rt, title = 'Precision vs. Recall', \n",
        "           labels = {\n",
        "             'x': 'Recall', \n",
        "             'y': 'Precision'\n",
        "           })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p5p88w1FjG9"
      },
      "outputs": [],
      "source": [
        "len(threshold_rt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poPUITiNFLW3"
      },
      "outputs": [],
      "source": [
        "# Grafica de todos los limites (threshold)\n",
        "plt.plot(threshold_rt[0:])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kRmyC5yAOOa"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x = threshold_rt, y = precision_rt[1:], name = \"Precision\"))\n",
        "fig.add_trace(go.Scatter(x = threshold_rt, y = recall_rt[1:], name = \"Recall\"))\n",
        "\n",
        "fig.update_layout(\n",
        "    title = 'Precision y Recall para diferentes umbrales', \n",
        "    xaxis_title = 'Umbral (threshold)', \n",
        "    yaxis_title = 'Precision/Recall', \n",
        "    hovermode=\"x unified\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko7GOs_PwO8P"
      },
      "outputs": [],
      "source": [
        "threshold_fixed = 47"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cT-BykvLC8uE"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                    x = error_df[error_df.True_class == 0].index.to_numpy(), \n",
        "                    y = error_df[error_df.True_class == 0].Reconstruction_error, \n",
        "                    mode = 'markers', \n",
        "                    name = 'Normal'))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "                    x = error_df[error_df.True_class == 1].index.to_numpy(), \n",
        "                    y = error_df[error_df.True_class == 1].Reconstruction_error, \n",
        "                    mode = 'markers', \n",
        "                    name = 'Fraude'))\n",
        "fig.add_hline(threshold_fixed, annotation_text = 'Umbral fijo', line_dash = 'dash')\n",
        "\n",
        "fig.update_layout(\n",
        "    title = 'Error de reconstrucción para distintas clases', \n",
        "    yaxis_title = 'Error de Reconstrucción (MSE)', \n",
        "    xaxis_title = 'Índice del punto'\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfNC1ncM779O"
      },
      "outputs": [],
      "source": [
        "pred_y = [1 if e > 47 else 0 for e in error_df.Reconstruction_error.values]\n",
        "conf_matrix = confusion_matrix(pred_y, error_df.True_class)\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "sns.heatmap(conf_matrix, xticklabels=['Normal', 'Fraude'], yticklabels=['Normal', 'Fraude'], annot=True, fmt=\"d\");\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPNYvvoH8DHV"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred_y, digits = 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUPTK6zV6AYp"
      },
      "source": [
        "# Ejercicios\n",
        "\n",
        "- Agregar más capas al encoder y/o al decoder y comparar los resultados obtenidos. Agregar muchas capas al modelo puede hacer que se sobreajuste. Una manera de mitigarlo es agregando regularización o capas Droupout. Si considera que su modelo tiene sobreajuste agregue cualquiera de las dos o elimine capas.\n",
        "- ¿Cuál es la utilidad de las funciones de activación? ¿Qué operaciones hacen las distintas [funciones de activación que tiene Keras](https://keras.io/api/layers/activations/)?\n",
        "- Pruebe con diferentes funciones de activación y evalue los resultados. Las funciones de activación que tiene el modelo son tanh (tangente hiperbólica) y ReLU (Rectified Linear Unit)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8lq6jZSJmfz"
      },
      "source": [
        "# Ligas\n",
        "\n",
        "- [Post Original](https://blogs.oracle.com/ai-and-datascience/post/fraud-detection-using-autoencoders-in-keras-with-a-tensorflow-backend)\n",
        "\n",
        "- Info. sobre pulir hiperparámetros (batch_size, learn_rate, epochs,...)\n",
        "  \n",
        "  *   https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/\n",
        "  *   https://www.oreilly.com/library/view/natural-language-processing/9781484242674/\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}