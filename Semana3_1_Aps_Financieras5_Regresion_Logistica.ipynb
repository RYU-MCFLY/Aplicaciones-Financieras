{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RYU-MCFLY/Aplicaciones-Financieras/blob/main/Semana3_1_Aps_Financieras5_Regresion_Logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MaxMitre/Aplicaciones-Financieras/blob/main/Semana3/1_Regresion_Logistica.ipynb)"
      ],
      "metadata": {
        "id": "bkUeov5T9Hfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descripción del problema"
      ],
      "metadata": {
        "id": "6DuKgmeStDUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datos originales: https://challengedata.ens.fr/participants/challenges/31/\n",
        "\n",
        "El problema trata de buscar un algoritmo de clasificación que ayude a crear estrategias de inversión en criptomonedas, basado en el \"sentimiento\" extraído de noticias y redes sociales.\n",
        "\n",
        "Por cada hora de trading se contabilizó la ocurrencia de algunos terminos, tales como 'adoption' y 'hack', en un selecto numero de cuentas influyentes de twitter y en algunos foros como 'Bitcointalk'.\n",
        "\n",
        "Se han creado 10 temas diferentes, algunos positivos y otros negativos y se han contabilizado las palabras antes mencionadas, antes de una normalización.\n",
        "\n",
        "Dado un tema, hemos visto los conteos de las últimas 48 horas y se estandarizaron esos conteos. El resultado se multiplicó por el conteo promedio por hora y se dividió por el conteo promedio por hora de todo el entrenamiento\n",
        "\n",
        "Para un tiempo T en el periodo de tiempo i, con lag k ($k\\in[\\![0;47]\\!]$) el valor F ode la característica será:\n",
        "\n",
        "$$\n",
        "F_{i,k}=\\frac{T_{i,k}-\\overline{T_{i}}}{\\sqrt{\\frac{1}{47}\\sum\\limits_{j=0}^{47}{(T_{i,j}-\\overline{T_{i}})^{2}}}}*\\frac{\\overline{T_i}}{\\overline{T}} \n",
        "$$\n",
        "\n",
        "\n",
        "Se agregaron 5 características correspondientes a los precios finales en periodos de 1 hr, 6 hrs, 12 hrs, 24 hrs y 48 hrs\n",
        "El objetivo es predecir si el precio del Bitcoin tendrá un retorno (en la próxima hora) que sea de mas del 0.2%, entre -0.2% y 0.2% o menos al -0.2%.\n",
        "\n",
        "La métrica utilizada para la perdida es la perdida logistica, definita como el negativo de la log-verosimilitud de las etiquetas verdaderas comparadas con las probabilidades predichas por el clasificador.\n",
        "\n",
        "Las verdaderas etiquetas están codificadas como una matríz de 3 columnas, donde hay unos o ceros dependiendo si el elemento pertenece a la categoría de una columna u otra.\n",
        " \n",
        "Dada una matriz P de probabilidades $p_{i,k}=Pr(t_{i,k}=1)'$ , la función de perdida se define como\n",
        "\n",
        "$$\n",
        "L_{log}(Y,P)=-log{Pr(Y|P)}=-\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{k=1}^3{y_{i,k}log(p_{i,k})}\n",
        "$$\n",
        "\n",
        "Entre más bajo el score de ésta medida, mejor.\n",
        "\n"
      ],
      "metadata": {
        "id": "E454T2Z7s_Tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencias"
      ],
      "metadata": {
        "id": "I1za57pz8Mkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U plotly"
      ],
      "metadata": {
        "id": "tIthEMHkPBww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Ifan8XrfuZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HV21Dtfz0SF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funciones"
      ],
      "metadata": {
        "id": "sqFcegOL8N7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(estimator, train, val, test):\n",
        "    print('train cross_entropy = ', estimator.evaluate(train[0], train[1], verbose = False))\n",
        "    print('  val cross_entropy = ', estimator.evaluate(val[0], val[1], verbose = False))\n",
        "    print(' test cross_entropy = ', estimator.evaluate(test[0], test[1], verbose = False))"
      ],
      "metadata": {
        "id": "Mv_00PdK2Wnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Modificar para seleccionar características cambiando n_features, no sólo las primeras n_features\n",
        "# TODO: Revisar los resultados generados cuando se seleccionan distintos parámetros\n",
        "# NOTE: Asuma que el dataframe tiene 5 X, y 48 columnas para cada una de las 10 I ordenadas de reciente a antigua\n",
        "def transform_dataframe(df, len_prices = 5, n_features = 10, len_features = 48):\n",
        "    if type(len_prices) != int or type(n_features) != int or type(len_features) != int:\n",
        "        raise ValueError(f'Los parámetros len_prices, n_features y len_features deben ser de tipo int. Recibibo {type(len_prices)},{type(n_features)} y {type(len_features)}')\n",
        "\n",
        "    assert 0 < len_prices <= 5, 'len_prices debe estar entre 1 y 5'\n",
        "    assert 0 < n_features <= 10, 'n_features debe estar entre 1 y 10'\n",
        "    assert 0 < len_features <= 48, 'len_features debe estar entre 1 y 48'\n",
        "\n",
        "    df.reset_index(inplace = True, drop = True)\n",
        "    \n",
        "    # Los nombres de las columnas están al reves para tener primer la observación más antigua\n",
        "    prices_cols = ['X5', 'X4', 'X3', 'X2', 'X1']\n",
        "\n",
        "    prices = np.zeros((len(df), len_prices, 1))\n",
        "    features = np.zeros((len(df), len_features, n_features))\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        # Se transforman la forma de los precios\n",
        "        prices[i] = df.loc[i, prices_cols[-len_prices:]].values.reshape((len_prices, 1))\n",
        "        # Para cada característica\n",
        "        for j in range(n_features):\n",
        "            # Se obtiene los 48 rezagos y se voltea el arreglo para tener el más antiguo primero\n",
        "            # Aquí se aplica el supuesto de que el dataframe tiene 5 columnas de 5\n",
        "            features[i, :, j] = np.flip(df.iloc[i, 5+48*j:5+len_features + 48*j].values)\n",
        "    return prices, features"
      ],
      "metadata": {
        "id": "pZ-N7rf_9HJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The Input data contains 10 time series of 48 trading hours representing complementary features based on sentiment analysis from news extracted from twitter or forums like Bitcointalk on Bitcoin, and 5 time series based on the variation of Bitcoin price during the past 1, 6, 12, 24 and 48 hours normalised by volatility during the period. Input data, for training and testing, will be given by a .csv file, whose first line contains the header. Then each line corresponds to a sample, each column to a feature. The features are the following:\n",
        "\n",
        ">- ***ID***: Id of the sample which is linked to the ID of the output file;\n",
        "- ***I_1_lag(k)*** to ***I_10_lag(k)***: Values of Indicators *I_1* to *I_10* for each k lag ($k\\in[\\![0;47]\\!]$) representing the normalized value of Indicators *I_1* to *I_10* each hour of the past 48 trading hours;\n",
        "- ***X_1*** to ***X_5***: Values of 5 normalised indicators representing price variation of Bitcoin on the last 1, 6, 12, 24 and 48 hours.\n",
        "\n",
        "> There will be 14 000 samples for the train set and 5 000 for the test set. For a given sample, the time series (for the 10 sentiment indicators) are given over the same 48 trading hours.\n",
        "\n",
        ">The training outputs are given in a .csv file. Each line corresponds to a sample:\n",
        "\n",
        ">- ***ID***: Id of the sample;\n",
        "- ***Target_-1***: classification of the return of Bitcoin in the next hour. -1 signifies a down move of less than -0.2%;\n",
        "- ***Target_0***: classification of the return of Bitcoin in the next hour. 0 signifies a move between -0.2% and 0.2%;\n",
        "- ***Target_1***: classification of the return of Bitcoin in the next hour. 1 signifies a up move of more than 0.2%.\n",
        "\n"
      ],
      "metadata": {
        "id": "XT_-69IHrvk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_raw = pd.read_csv('/content/drive/MyDrive/Cruso-ApsFinancieras/semana7/input_training_IrTAw7w.csv').set_index('ID')\n",
        "X_raw"
      ],
      "metadata": {
        "id": "x20PPm-uf29p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_raw = pd.read_csv('/content/drive/MyDrive/Cruso-ApsFinancieras/semana7/output_training_F2dZW38.csv').set_index('ID')\n",
        "y_raw"
      ],
      "metadata": {
        "id": "29-SdvrDk-lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## División: Entrenamiento, Validación y Prueba"
      ],
      "metadata": {
        "id": "4fqHIttJ8RTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Division para entrenamiento de red LSTM\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, train_size = .8, random_state = 10, shuffle = False)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size = .75, random_state = 10, shuffle = False)\n",
        "\n",
        "print('     Train shape', X_train.shape)\n",
        "print('Validation shape', X_val.shape)\n",
        "print('      Test shape', X_test.shape)"
      ],
      "metadata": {
        "id": "1X0rE_Qj1Ys0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformaciones"
      ],
      "metadata": {
        "id": "LV5EgGdD8WAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len_prices = 5\n",
        "n_features = 10\n",
        "len_features = 48\n",
        "\n",
        "train_prices, train_features = transform_dataframe(X_train, len_prices, n_features, len_features)\n",
        "val_prices, val_features     = transform_dataframe(X_val,   len_prices, n_features, len_features)\n",
        "test_prices, test_features   = transform_dataframe(X_test,  len_prices, n_features, len_features)"
      ],
      "metadata": {
        "id": "E9kHbyBf-hUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Labels: (samples, sequence length, features)')\n",
        "print('  Train prices:', train_prices.shape)\n",
        "print('Train features:', train_features.shape)"
      ],
      "metadata": {
        "id": "D9vHnzXOGlJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_prices[0].reshape(1,5,1)"
      ],
      "metadata": {
        "id": "DH0Jp5eG6aJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_prices[0]"
      ],
      "metadata": {
        "id": "21LUrTXG66Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritmos-Modelos"
      ],
      "metadata": {
        "id": "Z8wnN8eN8fbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión logística"
      ],
      "metadata": {
        "id": "NfcAiYGc994C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El punto de referencia de los propietarios de los datos es una regresión logística tomando como características X1, $\\dots$, X5."
      ],
      "metadata": {
        "id": "0B2PDjT2-_n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "XxRMOiQR2d3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impresion bonita de los números, sin notación científica\n",
        "np.set_printoptions(suppress=True)\n",
        "train_prices"
      ],
      "metadata": {
        "id": "hi_GmUvP3InB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_raw, y_raw, train_size = .8, random_state = 10, shuffle = False)"
      ],
      "metadata": {
        "id": "-gaJ6tl43i7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_0 = X_train_0[['X1', 'X2', 'X3', 'X4', 'X5']]\n",
        "X_train_0"
      ],
      "metadata": {
        "id": "ZF4hOjid3tza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_0 = X_test_0[['X1', 'X2', 'X3', 'X4', 'X5']]\n",
        "X_test_0"
      ],
      "metadata": {
        "id": "dJZBRMLB4ueT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_0"
      ],
      "metadata": {
        "id": "o_7JNo-aII09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_0 = y_train_0.idxmax(axis=1)\n",
        "y_train_0"
      ],
      "metadata": {
        "id": "0AOe0xet4bSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_0 = y_test_0.idxmax(axis=1)\n",
        "y_test_0"
      ],
      "metadata": {
        "id": "baOggV1r42-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = LogisticRegression(multi_class='multinomial', random_state=1)"
      ],
      "metadata": {
        "id": "RCCmUlbR1yPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ¿Que aparece al imprimir esta variable?\n",
        "model_0"
      ],
      "metadata": {
        "id": "AX6I3YOnOA1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.fit(X_train_0, y_train_0)"
      ],
      "metadata": {
        "id": "AHrjeE4N1yNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.coef_"
      ],
      "metadata": {
        "id": "3wY8xH3fimrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.intercept_"
      ],
      "metadata": {
        "id": "ZLaghB4eJUoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ¿como ver que atributos tiene mi objeto?\n",
        "dir(model_0)"
      ],
      "metadata": {
        "id": "zkgTFRwk_FrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.classes_"
      ],
      "metadata": {
        "id": "caCdwhN__U6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_0 = model_0.predict(X_test_0)"
      ],
      "metadata": {
        "id": "O4q32k1J1yLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_0"
      ],
      "metadata": {
        "id": "z4-uH5EkAaaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_0"
      ],
      "metadata": {
        "id": "xhOOBIvtjZnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Método para obtener las probabilidades de pertenencia a las clases\n",
        "y_probas = model_0.predict_proba(X_test_0)\n",
        "y_probas "
      ],
      "metadata": {
        "id": "Qn5Nyshojw3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pueden utilizar el minimo para explorar\n",
        "y_probas.max(axis=0)"
      ],
      "metadata": {
        "id": "f9DQEE_7kUGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(y_pred_0 == y_test_0)"
      ],
      "metadata": {
        "id": "rbPUcnv5CI1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(y_pred_0 == y_test_0).value_counts()"
      ],
      "metadata": {
        "id": "KKxKwdF7CWrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(y_pred_0 == y_test_0).sum() / len(y_pred_0)"
      ],
      "metadata": {
        "id": "dpulvfSw1yIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_0, y_pred_0))"
      ],
      "metadata": {
        "id": "tlJD5hYd1yGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "1pOr7LWI1yDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_test_0, y_pred_0)"
      ],
      "metadata": {
        "id": "ZCFn_Ufu1x7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss"
      ],
      "metadata": {
        "id": "vFAcWW8vJxse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_0"
      ],
      "metadata": {
        "id": "Q3iszsDTPFTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Valor de la función de perdida\n",
        "log_loss(y_test_0, model_0.predict_proba(X_test_0))"
      ],
      "metadata": {
        "id": "LaZDE91CJ1Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- ¿Que tan buenos son los resultados basados en la matriz de confusión?\n",
        "\n",
        "- ¿Qué podríamos hacer para mejorar el modelo?\n",
        "\n"
      ],
      "metadata": {
        "id": "9SB6tb6xLKiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio:\n",
        "\n",
        "Ejecutar el algoritmo de regresión logística para los datos de TRAIN que tenemos (se evaluó en datos de TEST pero no de TRAIN)\n",
        "\n",
        "- Clasification report\n",
        "- Matriz de confusión\n",
        "- Valor de la función de perdida"
      ],
      "metadata": {
        "id": "oSjHGSaLmSqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Espacio para ejercicio"
      ],
      "metadata": {
        "id": "srUh6cmsNgs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutar un algoritmo de clasificación con solo 2 CLASES (\"Target 1\" y \"Target -1\")"
      ],
      "metadata": {
        "id": "GmARGsCOEVw-"
      }
    }
  ]
}